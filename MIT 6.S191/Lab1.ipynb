{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yala/introdeeplearning  # Clone the full repo\n",
        "%cd introdeeplearning  # Move into the repo directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh0mQNfD6flp",
        "outputId": "3a6792a7-be62-4920-e2d1-18d4cef4c018"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'introdeeplearning'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Total 244 (delta 0), reused 0 (delta 0), pack-reused 244 (from 1)\u001b[K\n",
            "Receiving objects: 100% (244/244), 23.44 MiB | 10.78 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n",
            "[Errno 2] No such file or directory: 'introdeeplearning # Move into the repo directory'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow matplotlib pandas  # Install required packages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8devv8W7vc5",
        "outputId": "3cf75d8b-d676-4d95-bb0a-d98ab2a0dd25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload lab1_utils.py manually"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "oPJ_DZbv81p6",
        "outputId": "e7bbec1d-9c2a-4e81-a115-0d1b545187d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98e8d068-03b1-463e-be13-d585590c20fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-98e8d068-03b1-463e-be13-d585590c20fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lab1_utils.py to lab1_utils (1).py\n",
            "Saving preprocessing.py to preprocessing.py\n",
            "Saving special_tokens.py to special_tokens.py\n",
            "Saving utils.py to utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "y6lJSQHu6CTn"
      },
      "outputs": [],
      "source": [
        "import pickle as p\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import lab1_utils as utils\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLhe6uHa6CTp"
      },
      "source": [
        "# Intro to TensorFlow\n",
        "\n",
        "## What is a Computation Graph?\n",
        "\n",
        "Everything in TensorFlow comes down to building a computation graph. What is a computation graph? Its just a series of math operations that occur in some order. Here is an example of a simple computation graph:\n",
        "\n",
        "<img src=\"files/computation-graph.png\">\n",
        "\n",
        "This graph takes 2 inputs, (a, b) and computes an output (e). Each node in the graph is an operation that takes some input, does some computation, and passes its output to another node.\n",
        "\n",
        "We could make this computation graph in TensorFlow in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()  # Disable TF2 eager execution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEI6mSOW-3rP",
        "outputId": "9c0398d3-bbf9-40d8-d7d8-5c2b6b6d842c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RTV3sbML6CTs"
      },
      "outputs": [],
      "source": [
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "c = tf.add(a, b)\n",
        "d = tf.subtract(b, 1)\n",
        "e = tf.multiply(c, d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO9UOQ8b6CTt"
      },
      "source": [
        "Tensorflow uses tf.placeholder to handle inputs to the model. This is like making a reservation at a restaurant. The restaurant reserves a spot for 5 people, but you are free to fill those seats with any set of friends you want to. tf.placeholder lets you specify that some input will be coming in, of some shape and some type. Only when you run the computation graph do you actually provide the values of this input data. You would run this simple computation graph like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q60svoh6CTu",
        "outputId": "ff556fe1-8249-475d-a1ab-37f4faf16fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.float32(45.0)]\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as session:\n",
        "    a_data, b_data = 3.0, 6.0\n",
        "    feed_dict = {a: a_data, b: b_data}\n",
        "    output = session.run([e], feed_dict=feed_dict)\n",
        "    print(output) # 45.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X4zU0U26CTv"
      },
      "source": [
        "We use feed_dict to pass in the actual input data into the graph. We use session.run to get the output from the c operation in the graph. Since e is at the end of the graph, this ends up running the entire graph and returning the number 45 - cool!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "045A1sCS6CTv"
      },
      "source": [
        "## Neural Networks in Tensorflow\n",
        "\n",
        "We can define neural networks in TensorFlow using computation graphs. Here is an example, very simple neural network (just 1 perceptron):\n",
        "\n",
        "<img src=\"files/computation-graph-2.png\">\n",
        "\n",
        "This graph takes an input, (x) and computes an output (out). It does it with what we learned in class, `out = sigmoid(W*x+b)`.\n",
        "\n",
        "We could make this computation graph in TensorFlow in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5oBqLhvi6CTw"
      },
      "outputs": [],
      "source": [
        "n_input_nodes = 2\n",
        "n_output_nodes = 1\n",
        "x = tf.placeholder(tf.float32, (None, n_input_nodes))\n",
        "W = tf.Variable(tf.ones((n_input_nodes, n_output_nodes)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros(n_output_nodes), dtype=tf.float32)\n",
        "\n",
        "'''TODO: Define the operation for z (use tf.matmul to multiply W and x).'''\n",
        "z = tf.matmul(x, W) + b\n",
        "\n",
        "'''TODO: Define the operation for out (use tf.sigmoid).'''\n",
        "out = tf.sigmoid(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xwRHMae6CTx"
      },
      "source": [
        "To run this graph, we again use session.run() and feed in our input via feed_dict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRHbeL0i6CTy",
        "outputId": "4f72650c-a721-47db-9dec-2843f45e294b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7310586]]\n"
          ]
        }
      ],
      "source": [
        "test_input = [[0.5, 0.5]]\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run(session=session)\n",
        "    feed_dict = {x: test_input}\n",
        "    output = session.run([out], feed_dict=feed_dict)\n",
        "    print(output[0]) # This should output 0.73105. If not, double-check your code above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CcOZdxP6CTz"
      },
      "source": [
        "We can also set the value of a tf.Variable when we make it. Below is an example where we set the value of tf.Variable ourselves. We've made a classification dataset for you to play around with, and see how the decision boundary changes with the model parameters (weights and bias). Try to get all the datapoints correct (green)!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''TODO: manually optimize weight_values and bias_value to classify points'''\n",
        "\n",
        "# Modify weight_values, bias_value in the above code to adjust the decision boundary\n",
        "# See if you can classify all the points correctly (all markers green)\n",
        "\n",
        "weight_values = np.array([[-0.1], [0.2]]) # TODO change values and re-run\n",
        "bias_value = np.array([[0.5]]) #TODO change values and re-run\n",
        "\n",
        "# A pretty good boundary is made with:\n",
        "# weight_values = np.array([[0.03], [0.12]])\n",
        "# bias_value = np.array([[-0.5]])\n",
        "\n",
        "x = tf.placeholder(tf.float32, (None, 2), name='x')\n",
        "W = tf.Variable(weight_values, name='W', dtype=tf.float32)\n",
        "b = tf.Variable(bias_value, name='b', dtype=tf.float32)\n",
        "z = tf.matmul(x, W) + b\n",
        "out = tf.sigmoid(z)\n",
        "\n",
        "data = np.array([[2, 7], [1, 7], [3, 1], [3, 3], [4, 3], [4, 6], [6, 5], [7, 7], [7, 5], [2, 4], [2, 2]])\n",
        "y = np.array([1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run(session=session)\n",
        "    utils.classify_and_plot(data, y, x, out, session)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "Rz3iJfIOCK9f",
        "outputId": "c83f63eb-82c7-4b29-ae15-73d6effaf2c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions [array([[0.84553474]], dtype=float32), array([[0.85814893]], dtype=float32), array([[0.59868765]], dtype=float32), array([[0.6899745]], dtype=float32), array([[0.6681878]], dtype=float32), array([[0.78583497]], dtype=float32), array([[0.7109495]], dtype=float32), array([[0.76852477]], dtype=float32), array([[0.6899745]], dtype=float32), array([[0.7502601]], dtype=float32), array([[0.6681878]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''TODO: manually optimize weight_values and bias_value to classify points'''\n",
        "\n",
        "# Modified\n",
        "\n",
        "weight_values = np.array([[0.01], [0.12]])  # [weight_for_x1, weight_for_x2]\n",
        "bias_value = np.array([[-0.5]])            # bias term\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32, (None, 2), name='x')\n",
        "W = tf.Variable(weight_values, name='W', dtype=tf.float32)\n",
        "b = tf.Variable(bias_value, name='b', dtype=tf.float32)\n",
        "z = tf.matmul(x, W) + b\n",
        "out = tf.sigmoid(z)\n",
        "\n",
        "data = np.array([[2, 7], [1, 7], [3, 1], [3, 3], [4, 3], [4, 6], [6, 5], [7, 7], [7, 5], [2, 4], [2, 2]])\n",
        "y = np.array([1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run(session=session)\n",
        "    utils.classify_and_plot(data, y, x, out, session)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "OMVVjFWeCeh6",
        "outputId": "337187a5-281e-460f-c3f8-73b1af32451f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGeJJREFUeJzt3XtslfX9wPFPgVEaaBvFUU5nq50xP1S8IUoUMzSSEaM4tsTFBReGiVuyqmB3EbZg23ipl/2M8RK5/KEmEy/JgrfEJYRpjRGQixjNpmhGIjEF5iY9gLGa9vn98YvNKp2u8hzPl9PXKyHkPOfyfJ4cj8+b5zxPW5VlWRYAAAkZU+4BAAC+SKAAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyRlxoLz88ssxf/78aGxsjKqqqnj66aeH3J9lWdx8881RKBSipqYm5s6dG++++25e8wIAo8CIA+XQoUNx5plnxoMPPjjs/XfddVfcd999sXLlyti8eXNMnDgx5s2bF5988skRDwsAjA5VR/LLAquqqmLdunWxYMGCiPj/oyeNjY3xq1/9Kn79619HRERvb280NDTEI488EldddVUuQwMAlW1cni+2a9eu2LNnT8ydO3dwWX19fcyaNSs2btw4bKD09fVFX1/f4O2BgYH417/+FZMnT46qqqo8xwMASiTLsjhw4EA0NjbGmDFHfoprroGyZ8+eiIhoaGgYsryhoWHwvi/q6uqKzs7OPMcAAMpk9+7dcfzxxx/x6+QaKF/H8uXLo62tbfB2b29vNDc3x+7du6Ourq6MkwEA/61isRhNTU1RW1uby+vlGihTp06NiIi9e/dGoVAYXL53794466yzhn1OdXV1VFdXH7a8rq5OoADAUSav0zNy/TkoLS0tMXXq1NiwYcPgsmKxGJs3b47zzz8/z1UBABVsxEdQDh48GO+9997g7V27dsWOHTvi2GOPjebm5li6dGnceuutcfLJJ0dLS0usWLEiGhsbB6/0AQD4KiMOlK1bt8bFF188ePvz80cWLVoUjzzySPz2t7+NQ4cOxc9//vPYv39/XHjhhfHnP/85JkyYkN/UAEBFO6Kfg1IKxWIx6uvro7e31zkoAHCUyHv/7XfxAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQnNwDpb+/P1asWBEtLS1RU1MTJ510Utxyyy2RZVneqwIAKtS4vF/wzjvvjIceeigeffTROO2002Lr1q2xePHiqK+vjxtuuCHv1QEAFSj3QHn11VfjBz/4QVx22WUREXHiiSfG448/Hq+99lreqwIAKlTuX/FccMEFsWHDhti5c2dERLzxxhvxyiuvxKWXXjrs4/v6+qJYLA75AwCMbrkfQVm2bFkUi8WYNm1ajB07Nvr7++O2226LhQsXDvv4rq6u6OzszHsMAOAolvsRlKeeeioee+yxWLt2bWzfvj0effTR+MMf/hCPPvrosI9fvnx59Pb2Dv7ZvXt33iMBAEeZqizny2uamppi2bJl0draOrjs1ltvjT/+8Y/x9ttvf+Xzi8Vi1NfXR29vb9TV1eU5GgBQInnvv3M/gvLxxx/HmDFDX3bs2LExMDCQ96oAgAqV+zko8+fPj9tuuy2am5vjtNNOi9dffz3uueeeuOaaa/JeFQBQoXL/iufAgQOxYsWKWLduXezbty8aGxvjJz/5Sdx8880xfvz4r3y+r3gA4OiT9/4790A5UgIFAI4+yZ+DAgBwpAQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6CUSM+Bnuh4qSN6DvSUe5QjUinbARzO55uUCZQS6TnYE53dndFz8Oj+4FfKdgCH8/kmZQIFAEiOQAEAkiNQAIDkCBQAIDnjyj3A0a7nQM+wJ5ht79k+5O8vKkwqRKG2UNLZRqJStgM4nM83R6OqLMuycg/x74rFYtTX10dvb2/U1dWVe5yv1PFSR3R2d474ee1z2qPjoo78B/qaKmU7gMP5fPNNyHv/LVCO0Jf9y+Ta566NNfPXxIzCjMPuT+1fJpWyHcDhfL75JuS9//YVzxEq1H75B3hGYcawH/zUVMp2AIfz+eZo5CRZACA5AgUASI5AAQCSI1AAgOQIlBIpTCpE+5z2KEw6us+Ar5TtAA7n803KXGYMAByxvPffjqAAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREocJToOdATHS91RM+BnnKPAlByAgWOEj0He6KzuzN6DgoUoPIJFAAgOSUJlA8++CCuvvrqmDx5ctTU1MTpp58eW7duLcWqAIAKNC7vF/zoo49i9uzZcfHFF8cLL7wQ3/72t+Pdd9+NY445Ju9VAQAVKvdAufPOO6OpqSkefvjhwWUtLS15rwYAqGC5B8qzzz4b8+bNiyuvvDK6u7vjO9/5Tvzyl7+Ma6+9dtjH9/X1RV9f3+DtYrGY90hwVOk50DPsibDbe7YP+fuLCpMKUagtlHQ2gG9KVZZlWZ4vOGHChIiIaGtriyuvvDK2bNkSS5YsiZUrV8aiRYsOe3xHR0d0dnYetry3tzfq6uryHA2OCh0vdURn9+Gfia/SPqc9Oi7qyH8ggP9CsViM+vr63PbfuQfK+PHjY+bMmfHqq68OLrvhhhtiy5YtsXHjxsMeP9wRlKamJoHCqPVlR1Cufe7aWDN/TcwozDjsfkdQgHLKO1By/4qnUCjEqaeeOmTZKaecEn/605+GfXx1dXVUV1fnPQYctQq1Xx4aMwozhg0UgEqS+2XGs2fPjnfeeWfIsp07d8YJJ5yQ96oAgAqVe6DceOONsWnTprj99tvjvffei7Vr18bq1aujtbU171UBABUq90A599xzY926dfH444/H9OnT45Zbbol77703Fi5cmPeqAIAKlfs5KBERl19+eVx++eWleGkAYBTwu3jgKFGYVIj2Oe1RmORKHaDy5X6Z8ZHK+zIlAKD08t5/O4ICACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIwQj0HeqLjpY7oOdBT7lGOSKVsB5VJoACMUM/Bnujs7oyeg0f3jr1StoPKJFAAgOQIFAAgOQIFAEiOQAEAkjOu3AMApKrnQM+wJ5Bu79k+5O8vKkwqRKG2UNLZRqJStoPRpSrLsqzcQ/y7YrEY9fX10dvbG3V1deUeBxjFOl7qiM7uzhE/r31Oe3Rc1JH/QF9TpWwHact7/y1QAP6DLzvycO1z18aa+WtiRmHGYfenduShUraDtOW9//YVD8B/UKj98h30jMKMYXfsqamU7WB0cZIsAJAcgQIAJEegAADJESgAQHIECsAIFSYVon1OexQmHd1XuFTKdlCZXGYMAByxvPffjqAAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkpeaDccccdUVVVFUuXLi31qgCAClHSQNmyZUusWrUqzjjjjFKuBgCoMONK9cIHDx6MhQsXxpo1a+LWW2/9j4/r6+uLvr6+wdvFYrFUI/Eleg70RM/BnhE/rzCpEIXaQgkmAmA0K1mgtLa2xmWXXRZz58790kDp6uqKzs7OUo3Bf2nVtlXR2T3y96F9Tnt0XNSR/0AAjGolCZQnnngitm/fHlu2bPnKxy5fvjza2toGbxeLxWhqairFWHyJX5zzi7jif64Y8fMKkxw9ASB/uQfK7t27Y8mSJbF+/fqYMGHCVz6+uro6qqur8x6DESrU+qoGgHRUZVmW5fmCTz/9dPzwhz+MsWPHDi7r7++PqqqqGDNmTPT19Q2574uKxWLU19dHb29v1NXV5TkaAFAiee+/cz+Ccskll8Sbb745ZNnixYtj2rRpcdNNN31pnAAARJQgUGpra2P69OlDlk2cODEmT5582HIAgOH4SbIAQHJKdpnxv3vppZe+idUAABXCERQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5Iwr9wCQl54DPdFzsGfEzytMKkShtlCCib6eStkOgCMhUKgYq7atis7uzhE/r31Oe3Rc1JH/QF9TpWwHwJGoyrIsK/cQ/65YLEZ9fX309vZGXV1ducfhKFIpRx4qZTuA0SXv/bcjKFSMQm1l7KArZTsAjoSTZAGA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEhO7oHS1dUV5557btTW1saUKVNiwYIF8c477+S9GgCgguUeKN3d3dHa2hqbNm2K9evXx2effRbf//7349ChQ3mvCgCoUFVZlmWlXME//vGPmDJlSnR3d8f3vve9w+7v6+uLvr6+wdvFYjGampqit7c36urqSjka/6bnQE/0HOwZ8fMKkwpRqC2UYCIAjibFYjHq6+tz23+Py2GmL9Xb2xsREccee+yw93d1dUVnZ2epx+ArrNq2Kjq7R/4+tM9pj46LOvIfCIBRraRHUAYGBuKKK66I/fv3xyuvvDLsYxxBSYMjKAAciaPqCEpra2u89dZb/zFOIiKqq6ujurq6lGPwXyjUCg0A0lGyQLnuuuvi+eefj5dffjmOP/74Uq0GAKhAuQdKlmVx/fXXx7p16+Kll16KlpaWvFcBAFS43AOltbU11q5dG88880zU1tbGnj17IiKivr4+ampq8l4dAFCBcj9JtqqqatjlDz/8cPzsZz/7yufnfZINAFB6yZ8kW+IfqwIAjAJ+Fw8AkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcsaVewDIS8+Bnug52DPi5xUmFaJQWyjBRAB8XQKFirFq26ro7O4c8fPa57RHx0Ud+Q8EwNcmUKgYvzjnF3HF/1wx4ucVJjl6ApAagULFKNT6qgagUjhJFgBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOSULFAefPDBOPHEE2PChAkxa9aseO2110q1KgCgwpQkUJ588sloa2uL9vb22L59e5x55pkxb9682LdvXylWBwBUmKosy7K8X3TWrFlx7rnnxgMPPBAREQMDA9HU1BTXX399LFu2bMhj+/r6oq+vb/B2b29vNDc3x+7du6Ouri7v0QCAEigWi9HU1BT79++P+vr6I369cTnMNMSnn34a27Zti+XLlw8uGzNmTMydOzc2btx42OO7urqis7PzsOVNTU15jwYAlNg///nPNAPlww8/jP7+/mhoaBiyvKGhId5+++3DHr98+fJoa2sbvL1///444YQT4v33389lAzkynxexI1rl571Ih/ciHd6LdHz+Dcixxx6by+vlHigjVV1dHdXV1Yctr6+v9x9bQurq6rwfifBepMN7kQ7vRTrGjMnn9NbcT5I97rjjYuzYsbF3794hy/fu3RtTp07Ne3UAQAXKPVDGjx8f55xzTmzYsGFw2cDAQGzYsCHOP//8vFcHAFSgknzF09bWFosWLYqZM2fGeeedF/fee28cOnQoFi9e/JXPra6ujvb29mG/9uGb5/1Ih/ciHd6LdHgv0pH3e1GSy4wjIh544IG4++67Y8+ePXHWWWfFfffdF7NmzSrFqgCAClOyQAEA+Lr8Lh4AIDkCBQBIjkABAJIjUACA5CQXKA8++GCceOKJMWHChJg1a1a89tpr5R5p1Onq6opzzz03amtrY8qUKbFgwYJ45513yj0WEXHHHXdEVVVVLF26tNyjjFoffPBBXH311TF58uSoqamJ008/PbZu3VrusUad/v7+WLFiRbS0tERNTU2cdNJJccstt4TrPkrv5Zdfjvnz50djY2NUVVXF008/PeT+LMvi5ptvjkKhEDU1NTF37tx49913R7yepALlySefjLa2tmhvb4/t27fHmWeeGfPmzYt9+/aVe7RRpbu7O1pbW2PTpk2xfv36+Oyzz+L73/9+HDp0qNyjjWpbtmyJVatWxRlnnFHuUUatjz76KGbPnh3f+ta34oUXXoi//vWv8b//+79xzDHHlHu0UefOO++Mhx56KB544IH429/+FnfeeWfcddddcf/995d7tIp36NChOPPMM+PBBx8c9v677ror7rvvvli5cmVs3rw5Jk6cGPPmzYtPPvlkZCvKEnLeeedlra2tg7f7+/uzxsbGrKurq4xTsW/fviwisu7u7nKPMmodOHAgO/nkk7P169dnc+bMyZYsWVLukUalm266KbvwwgvLPQZZll122WXZNddcM2TZj370o2zhwoVlmmh0iohs3bp1g7cHBgayqVOnZnfffffgsv3792fV1dXZ448/PqLXTuYIyqeffhrbtm2LuXPnDi4bM2ZMzJ07NzZu3FjGyejt7Y2IyO03VDJyra2tcdlllw35fPDNe/bZZ2PmzJlx5ZVXxpQpU+Lss8+ONWvWlHusUemCCy6IDRs2xM6dOyMi4o033ohXXnklLr300jJPNrrt2rUr9uzZM+T/VfX19TFr1qwR78vL/tuMP/fhhx9Gf39/NDQ0DFne0NAQb7/9dpmmYmBgIJYuXRqzZ8+O6dOnl3ucUemJJ56I7du3x5YtW8o9yqj397//PR566KFoa2uL3/3ud7Fly5a44YYbYvz48bFo0aJyjzeqLFu2LIrFYkybNi3Gjh0b/f39cdttt8XChQvLPdqotmfPnoiIYffln9/330omUEhTa2trvPXWW/HKK6+Ue5RRaffu3bFkyZJYv359TJgwodzjjHoDAwMxc+bMuP322yMi4uyzz4633norVq5cKVC+YU899VQ89thjsXbt2jjttNNix44dsXTp0mhsbPReVIhkvuI57rjjYuzYsbF3794hy/fu3RtTp04t01Sj23XXXRfPP/98vPjii3H88ceXe5xRadu2bbFv376YMWNGjBs3LsaNGxfd3d1x3333xbhx46K/v7/cI44qhUIhTj311CHLTjnllHj//ffLNNHo9Zvf/CaWLVsWV111VZx++unx05/+NG688cbo6uoq92ij2uf76zz25ckEyvjx4+Occ86JDRs2DC4bGBiIDRs2xPnnn1/GyUafLMviuuuui3Xr1sVf/vKXaGlpKfdIo9Yll1wSb775ZuzYsWPwz8yZM2PhwoWxY8eOGDt2bLlHHFVmz5592CX3O3fujBNOOKFME41eH3/8cYwZM3QXNnbs2BgYGCjTREREtLS0xNSpU4fsy4vFYmzevHnE+/KkvuJpa2uLRYsWxcyZM+O8886Le++9Nw4dOhSLFy8u92ijSmtra6xduzaeeeaZqK2tHfzesL6+Pmpqaso83ehSW1t72Lk/EydOjMmTJzsnqAxuvPHGuOCCC+L222+PH//4x/Haa6/F6tWrY/Xq1eUebdSZP39+3HbbbdHc3BynnXZavP7663HPPffENddcU+7RKt7BgwfjvffeG7y9a9eu2LFjRxx77LHR3NwcS5cujVtvvTVOPvnkaGlpiRUrVkRjY2MsWLBgZCvK6Uqj3Nx///1Zc3NzNn78+Oy8887LNm3aVO6RRp2IGPbPww8/XO7RyDKXGZfZc889l02fPj2rrq7Opk2blq1evbrcI41KxWIxW7JkSdbc3JxNmDAh++53v5v9/ve/z/r6+so9WsV78cUXh91HLFq0KMuy/7/UeMWKFVlDQ0NWXV2dXXLJJdk777wz4vVUZZkfuwcApCWZc1AAAD4nUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDn/B3HDkT8/97G9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions [array([[0.5890404]], dtype=float32), array([[0.5866176]], dtype=float32), array([[0.4133824]], dtype=float32), array([[0.47252768]], dtype=float32), array([[0.4750208]], dtype=float32), array([[0.5646363]], dtype=float32), array([[0.53991485]], dtype=float32), array([[0.6010878]], dtype=float32), array([[0.542398]], dtype=float32), array([[0.5]], dtype=float32), array([[0.44028637]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JwB7q2n6CTz"
      },
      "source": [
        "## Tweet Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LtvItgK6CT0"
      },
      "source": [
        "Let's move to a real-world task. We're going to be classifying tweets as positive, negative, or neutral. Check out the very negative tweet below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPLKAcP76CT0"
      },
      "source": [
        "<img src=\"files/tweet-model.jpg\" style=\"width: 500px;\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me8t4aWU6CT0"
      },
      "source": [
        "## Building the Model\n",
        "\n",
        "### Building an MLP\n",
        "\n",
        "MLP or Multi-layer perceptron is a basic archetecture where where we multiply our representation with some matrix `W` and add some bias `b` and then apply some nonlinearity like `tanh` at each layer. Layers are fully connected to the next. As the network gets deeper, it's expressive power grows exponentially and so they can draw some pretty fancy decision boundaries. In this exercise, you'll build your own MLP, with 2 hidden layers (layers that aren't input or output).\n",
        "\n",
        "To make training more stable and efficient, we'll actually evaluate 128 tweets at a time, and take gradients with respect to the loss on the 128. We call this idea **training with mini-batches**.\n",
        "\n",
        "### Step 1: Representing Words\n",
        "\n",
        "In this model, well be representing tweets as [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) (BOW) representations. BOW representations are vectors where each element index represents a different word and its value represents the number of times this word appears in our sentence. This means that each sentence will be represented by a vector that is vocab_size long. Our output labels will be represented as a vector of size n_classes (3). We get this data with some utility functions:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload sentiment-tweets.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "iT7oHzgfFCMh",
        "outputId": "ebc66d5e-723e-42c3-859d-58b340eefd1a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-24faa057-b73b-4256-a012-6d0ef742be01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-24faa057-b73b-4256-a012-6d0ef742be01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sentiment-tweets.csv to sentiment-tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./data  # Create data directory if it doesn't exist\n",
        "!mv sentiment-tweets.csv ./data/  # Move the file"
      ],
      "metadata": {
        "id": "NvCp5m0-GEZX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./data/  # Should show sentiment-tweets.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijtKRbA3GHOD",
        "outputId": "63589d2c-61d1-4e99-cdaf-7bcbde5a1391"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment-tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('./data/sentiment-tweets.csv').head()  # Test loading directly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "pPiUar-_GTbB",
        "outputId": "ff6d7480-c9bc-4cb2-a5cb-bc215af8c37f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61717c36-da57-4958-a1d9-6638b8ddd5b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61717c36-da57-4958-a1d9-6638b8ddd5b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61717c36-da57-4958-a1d9-6638b8ddd5b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61717c36-da57-4958-a1d9-6638b8ddd5b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-727303bd-84c2-4981-89e0-e49d34556a78\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-727303bd-84c2-4981-89e0-e49d34556a78')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-727303bd-84c2-4981-89e0-e49d34556a78 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_2Lchiz6CT0",
        "outputId": "121b04ae-ec15-4ea6-b1ed-329a633d17d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
            "it's really the only bad thing about flying VA\n",
            "Label: [0. 0. 1.]\n",
            "Bag of Words Representation: [0. 1. 0. ... 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "X, y, index_to_word, sentences = utils.load_sentiment_data_bow()\n",
        "X_train, y_train, X_test, y_test = utils.split_data(X, y)\n",
        "vocab_size = X.shape[1]\n",
        "n_classes = y.shape[1]\n",
        "\n",
        "print(\"Tweet:\", sentences[5])\n",
        "print(\"Label:\", y[5])\n",
        "print(\"Bag of Words Representation:\", X_train[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odpYoxFl6CT1"
      },
      "source": [
        "### Step 2: Making Placeholders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uug8nBdd6CT1"
      },
      "source": [
        "So we have our data loaded as numpy arrays. But remember, TensorFlow graphs begin with generic placeholder inputs, not actual data. We feed the actual data in later once the full graph has been defined. We define our placeholders like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JMhY61HY6CT1"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "data_placeholder = tf.placeholder(tf.float32, shape=(None, vocab_size), name='data_placeholder')\n",
        "\n",
        "'''TODO: Make the labels placeholder.'''\n",
        "labels_placeholder = tf.placeholder(tf.float32, shape=(None, n_classes), name='labels_placeholder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSYspM_F6CT1"
      },
      "source": [
        "#### Why Do We Pass in None?\n",
        "\n",
        "A note about None and fluid-sized dimensions:\n",
        "\n",
        "You may notice that the first dimension of shape of data_placeholder is None. data_placeholder should have shape (num_tweets, vocab_size). However, we dont know how many tweets we are going to be passing in at a time, num_tweets is unknown. Its possible that we only want to pass in 1 tweet at a time, or 30, or 1,000. Thankfully, TensorFlow allows us to specify placeholders with fluid-sized dimensions. We can use None to specify some fluid dimension of our shape. When our data eventually gets passed in as a numpy array, TensorFlow can figure out what the value of the fluid-size dimension should be.\n",
        "\n",
        "### Step 3: Define Network Parameters\n",
        "Lets now define and initialize our network parameters.\n",
        "\n",
        "We'll our model parameters using tf.Variable. When you create a tf.Variable you pass a Tensor as its initial value to the Variable() constructor. A Tensor is a term for any N-dimensional matrix. There are a ton of different initial Tensor value functions you can use ([full list](https://www.tensorflow.org/api_docs/python/constant_op/)). All these functions take a list argument that determines their shape. Here we use tf.truncated_normal for our weights, and tf.zeros for our biases. Its important that the shape of these parameters are compatible. Well be matrix-multiplying the weights, so the last dimension of the previous weight matrix must equal the first dimension of the next weight matrix. Notice this pattern in the following tensor initialization code. Lastly, notice the size of the tensor for our last weights. We are predicting a vector of size n_classes so our network needs to end with n_classes nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pSuLzOsJ6CT2"
      },
      "outputs": [],
      "source": [
        "# Define Network Parameters\n",
        "\n",
        "# Here, we can define how many units will be in each hidden layer.\n",
        "n_hidden_units_h0 = 512\n",
        "n_hidden_units_h1 = 256\n",
        "\n",
        "# Weights going from input to first hidden layer.\n",
        "# The first value passed into tf.Variable is initialization of the variable.\n",
        "# We initialize our weights to be sampled from a truncated normal, as this does something\n",
        "# called symmetry breaking and keeps the neural network from getting stuck at the start.\n",
        "# Since the weight matrix multiplies the previous layer to get inputs to the next layer,\n",
        "# its size is prev_layer_size x next_layer_size.\n",
        "h0_weights = tf.Variable(\n",
        "    tf.truncated_normal([vocab_size, n_hidden_units_h0]),\n",
        "    name='h0_weights')\n",
        "h0_biases = tf.Variable(tf.zeros([n_hidden_units_h0]),\n",
        "                     name='h0_biases')\n",
        "\n",
        "'''TODO: Set up variables for the weights going into the second hidden layer.\n",
        "You can check out the tf.Variable API here: https://www.tensorflow.org/api_docs/python/tf/Variable.\n",
        "''';\n",
        "# Weights going from first hidden layer (h0) to second hidden layer (h1)\n",
        "h1_weights = tf.Variable(\n",
        "    tf.truncated_normal([n_hidden_units_h0, n_hidden_units_h1]),  # [input_size, output_size]\n",
        "    name='h1_weights')\n",
        "\n",
        "h1_biases = tf.Variable(\n",
        "    tf.zeros([n_hidden_units_h1]),  # matches the output size\n",
        "    name='h1_biases')\n",
        "# Weights going into the output layer.\n",
        "out_weights = tf.Variable(\n",
        "    tf.truncated_normal([n_hidden_units_h1, n_classes]),\n",
        "    name='out_weights')\n",
        "out_biases = tf.Variable(tf.zeros([n_classes]),\n",
        "                     name='out_biases')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R98TfFg6CT2"
      },
      "source": [
        "### Step 4: Build Computation Graph\n",
        "\n",
        "Now lets define our computation graph.\n",
        "\n",
        "Our first operation in our graph is a tf.matmul of our data input and our first set of weights. tf.matmul performs a matrix multiplication of two tensors. This is why it is so important that the dimensions of data_placeholder and h0_weights align (dimension 1 of data_placeholder must equal dimension 0 of h0_weights). We then just add the h0_bias variable and perform a nonlinearity transformation, in this case we use tf.nn.relu (ReLU). We do this again for the next hidden layer, and the final output logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "R39bzJgg6CT3"
      },
      "outputs": [],
      "source": [
        "# Define Computation Graphs\n",
        "hidden0 = tf.nn.relu(tf.matmul(data_placeholder, h0_weights) + h0_biases)\n",
        "\n",
        "'''TODO: write the computation to get the output of the second hidden layer.''';\n",
        "hidden1 = tf.nn.relu(tf.matmul(hidden0, h1_weights) + h1_biases)\n",
        "\n",
        "logits = tf.matmul(hidden1, out_weights) + out_biases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pAro-KZ6CT3"
      },
      "source": [
        "### Step 5: Define a Loss Functions\n",
        "\n",
        "We have defined our network, but we need a way to train it. Training a network comes down to optimizing our network to minimize a loss function, or a measure how good we're doing.  Then, we can take the gradient with respect to that performance and move in the right direction.\n",
        "\n",
        "Since we are doing classification (pos vs neg), a common loss function to use is [cross entropy](https://colah.github.io/posts/2015-09-Visual-Information/):\n",
        "\n",
        "$$L( \\Theta ) = - \\sum_i  y_i'\\log{y_i}  $$\n",
        "\n",
        "where $y$ is our predicted probability distribution and $y'$ is the true distribution. We can access this function in tensorflow with `tf.nn.softmax_cross_entropy_with_logits`.\n",
        "\n",
        "Note that this loss is 0 if the prediction is correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jFglc_I6CT3",
        "outputId": "573c7677-a5e9-4dc4-9d3b-3a1013bf0e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py:1260: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''TODO: Define the loss.  Use tf.nn.softmax_cross_entropy_with_logits.'''\n",
        "loss = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(\n",
        "        labels=labels_placeholder,\n",
        "        logits=logits\n",
        "    )\n",
        ")\n",
        "\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# Define the optimizer operation.  This is what will take the derivate of the loss\n",
        "# with respect to each of our parameters and try to minimize it.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Compute the accuracy\n",
        "prediction_is_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_placeholder, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction_is_correct, tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hg_qnfL6CT4"
      },
      "source": [
        "#### Quick Conceptual Note:\n",
        "Nearly everything we do in TensorFlow is an operation with inputs and outputs. Our loss variable is an operation, that takes the output of the last layer of the net, which takes the output of the 2nd-to-last layer of the net, and so on. Our loss can be traced back to the input as a single function. This is our full computation graph. We pass this to our optimizer which is able to compute the gradient for this computation graph and adjust all the weights in it to minimize the loss.\n",
        "\n",
        "### Step 6: Training our Net\n",
        "We have our network, our loss function, and our optimizer ready, now we just need to pass in the data to train it. We pass in the data in chunks called mini-batches.  We do backpropogation at the end of a batch based on the loss that results from all the examples in the batch.  Using batches is just like Stochastic Gradient Descent, except instead of updating parameters after each example, we update them based on the gradient computed after *several* examples.\n",
        "\n",
        "To measure how well we're doing, we can't just look at how well our model performs on it's training data. It could be just memorizing the training data and perform terribly on data it hasn't seen before. To really measure how it performs in the wild, we need to present it with unseen data, and we can tune our hyper-parameters (like learning rate, num layers etc.) over this first unseen set, which we call our development (or validation) set. However, given that we optimized our hyper-parameters to the development set, to get a true fair assesment of the model, we test it with respect to a held-out test set at the end, and generally report those numbers.\n",
        "\n",
        "For now, we'll just use a training set and a testing set.  We'll train with the training set and evaluate on the test set to see how well our model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-J6F3Bz6CT4",
        "outputId": "319f07dc-5223-4aac-b1ab-8342a4df00d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minibatch train loss at step 0 : 634.03784\n",
            "Minibatch train accuracy: 29.688%\n",
            "Test loss: 838.118\n",
            "Test accuracy: 15.301%\n",
            "Minibatch train loss at step 100 : 196.17879\n",
            "Minibatch train accuracy: 52.344%\n",
            "Test loss: 212.735\n",
            "Test accuracy: 53.040%\n",
            "Minibatch train loss at step 200 : 183.06631\n",
            "Minibatch train accuracy: 57.812%\n",
            "Test loss: 182.480\n",
            "Test accuracy: 56.352%\n",
            "Minibatch train loss at step 300 : 181.54999\n",
            "Minibatch train accuracy: 60.938%\n",
            "Test loss: 167.239\n",
            "Test accuracy: 55.943%\n",
            "Minibatch train loss at step 400 : 155.59077\n",
            "Minibatch train accuracy: 53.125%\n",
            "Test loss: 157.115\n",
            "Test accuracy: 56.182%\n",
            "Minibatch train loss at step 500 : 192.3277\n",
            "Minibatch train accuracy: 44.531%\n",
            "Test loss: 153.651\n",
            "Test accuracy: 54.918%\n",
            "Minibatch train loss at step 600 : 126.33103\n",
            "Minibatch train accuracy: 53.906%\n",
            "Test loss: 144.909\n",
            "Test accuracy: 55.225%\n",
            "Minibatch train loss at step 700 : 188.81761\n",
            "Minibatch train accuracy: 49.219%\n",
            "Test loss: 143.301\n",
            "Test accuracy: 55.567%\n",
            "Minibatch train loss at step 800 : 88.486465\n",
            "Minibatch train accuracy: 70.312%\n",
            "Test loss: 133.385\n",
            "Test accuracy: 56.557%\n",
            "Minibatch train loss at step 900 : 93.49062\n",
            "Minibatch train accuracy: 71.875%\n",
            "Test loss: 124.583\n",
            "Test accuracy: 59.119%\n",
            "Minibatch train loss at step 1000 : 99.999985\n",
            "Minibatch train accuracy: 56.250%\n",
            "Test loss: 123.054\n",
            "Test accuracy: 58.197%\n",
            "Minibatch train loss at step 1100 : 78.809074\n",
            "Minibatch train accuracy: 65.625%\n",
            "Test loss: 115.859\n",
            "Test accuracy: 60.314%\n",
            "Minibatch train loss at step 1200 : 105.88916\n",
            "Minibatch train accuracy: 58.594%\n",
            "Test loss: 111.851\n",
            "Test accuracy: 60.690%\n",
            "Minibatch train loss at step 1300 : 93.79593\n",
            "Minibatch train accuracy: 67.188%\n",
            "Test loss: 110.331\n",
            "Test accuracy: 60.007%\n",
            "Minibatch train loss at step 1400 : 111.805435\n",
            "Minibatch train accuracy: 51.562%\n",
            "Test loss: 110.269\n",
            "Test accuracy: 59.051%\n",
            "Minibatch train loss at step 1500 : 77.94331\n",
            "Minibatch train accuracy: 57.031%\n",
            "Test loss: 106.765\n",
            "Test accuracy: 60.109%\n",
            "Minibatch train loss at step 1600 : 77.39082\n",
            "Minibatch train accuracy: 56.250%\n",
            "Test loss: 103.784\n",
            "Test accuracy: 60.895%\n",
            "Minibatch train loss at step 1700 : 45.176495\n",
            "Minibatch train accuracy: 79.688%\n",
            "Test loss: 106.487\n",
            "Test accuracy: 58.470%\n",
            "Minibatch train loss at step 1800 : 61.994583\n",
            "Minibatch train accuracy: 75.781%\n",
            "Test loss: 99.179\n",
            "Test accuracy: 61.100%\n",
            "Minibatch train loss at step 1900 : 68.53587\n",
            "Minibatch train accuracy: 71.875%\n",
            "Test loss: 98.769\n",
            "Test accuracy: 60.587%\n",
            "Minibatch train loss at step 2000 : 70.69742\n",
            "Minibatch train accuracy: 71.875%\n",
            "Test loss: 95.600\n",
            "Test accuracy: 61.305%\n",
            "Minibatch train loss at step 2100 : 84.168884\n",
            "Minibatch train accuracy: 58.594%\n",
            "Test loss: 91.899\n",
            "Test accuracy: 62.227%\n",
            "Minibatch train loss at step 2200 : 110.44867\n",
            "Minibatch train accuracy: 59.375%\n",
            "Test loss: 92.036\n",
            "Test accuracy: 60.929%\n",
            "Minibatch train loss at step 2300 : 72.95439\n",
            "Minibatch train accuracy: 60.938%\n",
            "Test loss: 92.159\n",
            "Test accuracy: 59.734%\n",
            "Minibatch train loss at step 2400 : 96.80585\n",
            "Minibatch train accuracy: 53.906%\n",
            "Test loss: 92.837\n",
            "Test accuracy: 59.290%\n",
            "Minibatch train loss at step 2500 : 80.03327\n",
            "Minibatch train accuracy: 56.250%\n",
            "Test loss: 89.021\n",
            "Test accuracy: 60.212%\n",
            "Minibatch train loss at step 2600 : 99.5417\n",
            "Minibatch train accuracy: 54.688%\n",
            "Test loss: 87.335\n",
            "Test accuracy: 60.861%\n",
            "Minibatch train loss at step 2700 : 46.5647\n",
            "Minibatch train accuracy: 75.000%\n",
            "Test loss: 85.356\n",
            "Test accuracy: 60.690%\n",
            "Minibatch train loss at step 2800 : 44.819855\n",
            "Minibatch train accuracy: 75.781%\n",
            "Test loss: 83.236\n",
            "Test accuracy: 62.056%\n",
            "Minibatch train loss at step 2900 : 77.8118\n",
            "Minibatch train accuracy: 57.031%\n",
            "Test loss: 82.490\n",
            "Test accuracy: 61.475%\n"
          ]
        }
      ],
      "source": [
        "num_steps = 3000\n",
        "batch_size = 128\n",
        "\n",
        "with tf.Session() as session:\n",
        "\n",
        "    # this operation initializes all the variables we made earlier.\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        # Generate a minibatch.\n",
        "        offset = (step * batch_size) % (X_train.shape[0] - batch_size)\n",
        "        batch_data = X_train[offset:(offset + batch_size), :]\n",
        "        batch_labels = y_train[offset:(offset + batch_size), :]\n",
        "\n",
        "        # Create a dictionary to pass in the batch data.\n",
        "        feed_dict_train = {data_placeholder: batch_data, labels_placeholder : batch_labels}\n",
        "\n",
        "        # Run the optimizer, the loss, the predictions.\n",
        "        # We can run multiple things at once and get their outputs.\n",
        "        _, loss_value_train, predictions_value_train, accuracy_value_train = session.run(\n",
        "          [optimizer, loss, prediction, accuracy], feed_dict=feed_dict_train)\n",
        "\n",
        "        # Print stuff every once in a while.\n",
        "        if (step % 100 == 0):\n",
        "            print(\"Minibatch train loss at step\", step, \":\", loss_value_train)\n",
        "            print(\"Minibatch train accuracy: %.3f%%\" % (accuracy_value_train*100))\n",
        "            feed_dict_test = {data_placeholder: X_test, labels_placeholder: y_test}\n",
        "            loss_value_test, predictions_value_test, accuracy_value_test = session.run(\n",
        "                [loss, prediction, accuracy], feed_dict=feed_dict_test)\n",
        "            print(\"Test loss: %.3f\" % loss_value_test)\n",
        "            print(\"Test accuracy: %.3f%%\" % (accuracy_value_test*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Ei2k7G6CT4"
      },
      "source": [
        "Running this code, youll see the network train and output its performance as it learns. I was able to get it to 65.5% accuracy. This is just OK, considering random guessing gets you 33.3% accuracy. In the next tutorial, you'll learn some ways to improve upon this.\n",
        "\n",
        "## Concluding Thoughts\n",
        "This was a brief introduction into TensorFlow. There is so, so much more to learn and explore, but hopefully this has given you some base knowledge to expand upon. As an additional exercise, you can see what you can do with this code to improve the performance. Ideas include: randomizing mini-batches, making the network deeper, using word embeddings (see below) rather than bag-of-words, trying different optimizers (like Adam), different weight initializations. Well explore some of these tomorrow.\n",
        "\n",
        "#### More on Word Embeddings\n",
        "\n",
        "In this lab we used Bag-of-Words to represent a tweet.  Word Embeddings are a more meaningful representation.  The basic idea is we represent a word with a vector $\\phi$ by the context the word appears in. We do this by training a neural network to predict the context of words across a large training set. The weights of that neural network can then be thought of as a dense and useful representation that captures context. This is useful because now our representations of words captures actual semantic similarity.\n",
        "\n",
        "Word Embeddings capture all kinds of useful semantic relationships. For example, one cool emergent property is $ \\phi(king) - \\phi(queen) = \\phi(man) - \\phi(woman)$. To learn more about the magic behind word embeddings we recommend Chris Olah's [blog post](https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/). A common tool for generating Word Embeddings is word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YALsTYmH6CT4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5EGqsD7i6CT4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYHtUJnuSY_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cBvvB4t46CT4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eqc0SwHu6CT5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okXUJZJI6CT5"
      },
      "source": [
        "# Solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rvj4gey6CT5",
        "outputId": "d8a4a6db-4da7-4227-cede-605f14cb07d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[45.0]\n",
            "[[ 0.7310586]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFkCAYAAACw3EhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x11ad3e390>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFdCAYAAAAXGYTVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxXQgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x11ae7b910>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('predictions', [array([[ 0.59868765]], dtype=float32), array([[ 0.59145898]], dtype=float32), array([[ 0.42800382]], dtype=float32), array([[ 0.48750263]], dtype=float32), array([[ 0.49500021]], dtype=float32), array([[ 0.58419055]], dtype=float32), array([[ 0.56954622]], dtype=float32), array([[ 0.6341356]], dtype=float32), array([[ 0.57688522]], dtype=float32), array([[ 0.50999868]], dtype=float32), array([[ 0.45016602]], dtype=float32)])\n",
            "('Tweet:', \"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\")\n",
            "('Label:', array([ 0.,  0.,  1.]))\n",
            "('Bag of Words Representation:', array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
            "('Minibatch train loss at step', 0, ':', 430.91733)\n",
            "Minibatch train accuracy: 35.938%\n",
            "Test loss: 344.188\n",
            "Test accuracy: 40.027%\n",
            "('Minibatch train loss at step', 100, ':', 220.52003)\n",
            "Minibatch train accuracy: 54.688%\n",
            "Test loss: 244.641\n",
            "Test accuracy: 46.960%\n",
            "('Minibatch train loss at step', 200, ':', 182.77231)\n",
            "Minibatch train accuracy: 64.844%\n",
            "Test loss: 210.671\n",
            "Test accuracy: 50.239%\n",
            "('Minibatch train loss at step', 300, ':', 182.31335)\n",
            "Minibatch train accuracy: 51.562%\n",
            "Test loss: 199.027\n",
            "Test accuracy: 50.307%\n",
            "('Minibatch train loss at step', 400, ':', 193.7272)\n",
            "Minibatch train accuracy: 44.531%\n",
            "Test loss: 201.066\n",
            "Test accuracy: 47.165%\n",
            "('Minibatch train loss at step', 500, ':', 210.07607)\n",
            "Minibatch train accuracy: 39.062%\n",
            "Test loss: 205.993\n",
            "Test accuracy: 44.775%\n",
            "('Minibatch train loss at step', 600, ':', 202.87286)\n",
            "Minibatch train accuracy: 44.531%\n",
            "Test loss: 182.984\n",
            "Test accuracy: 47.268%\n"
          ]
        }
      ],
      "source": [
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "c = tf.add(a, b)\n",
        "d = tf.subtract(b, 1)\n",
        "e = tf.multiply(c, d)\n",
        "\n",
        "with tf.Session() as session:\n",
        "    a_data, b_data = 3.0, 6.0\n",
        "    feed_dict = {a: a_data, b: b_data}\n",
        "    output = session.run([e], feed_dict=feed_dict)\n",
        "    print(output) # 45.0\n",
        "\n",
        "n_input_nodes = 2\n",
        "n_output_nodes = 1\n",
        "x = tf.placeholder(tf.float32, (None, n_input_nodes))\n",
        "W = tf.Variable(tf.ones((n_input_nodes, n_output_nodes)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros(n_output_nodes), dtype=tf.float32)\n",
        "\n",
        "'''TODO: Define the operation for z (use tf.matmul to multiply W and x).'''\n",
        "z = tf.matmul(x, W) + b\n",
        "\n",
        "'''TODO: Define the operation for out (use tf.sigmoid).'''\n",
        "out = tf.sigmoid(z)\n",
        "\n",
        "\n",
        "test_input = [[0.5, 0.5]]\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run(session=session)\n",
        "    feed_dict = {x: test_input}\n",
        "    output = session.run([out], feed_dict=feed_dict)\n",
        "    print(output[0]) # This should output 0.73105. If not, double-check your code above\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''TODO: manually optimize weight_values and bias_value to classify points'''\n",
        "\n",
        "# Modify weight_values, bias_value in the above code to adjust the decision boundary\n",
        "# See if you can classify all the points correctly (all markers green)\n",
        "\n",
        "weight_values = np.array([[-0.1], [0.2]]) # TODO change values and re-run\n",
        "bias_value = np.array([[0.5]]) #TODO change values and re-run\n",
        "\n",
        "# A pretty good boundary is made with:\n",
        "weight_values = np.array([[0.03], [0.12]])\n",
        "bias_value = np.array([[-0.5]])\n",
        "\n",
        "x = tf.placeholder(tf.float32, (None, 2), name='x')\n",
        "W = tf.Variable(weight_values, name='W', dtype=tf.float32)\n",
        "b = tf.Variable(bias_value, name='b', dtype=tf.float32)\n",
        "z = tf.matmul(x, W) + b\n",
        "out = tf.sigmoid(z)\n",
        "\n",
        "data = np.array([[2, 7], [1, 7], [3, 1], [3, 3], [4, 3], [4, 6], [6, 5], [7, 7], [7, 5], [2, 4], [2, 2]])\n",
        "y = np.array([1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run(session=session)\n",
        "    utils.classify_and_plot(data, y, x, out, session)\n",
        "\n",
        "\n",
        "\n",
        "# load data\n",
        "X, y, index_to_word, sentences = utils.load_sentiment_data_bow()\n",
        "X_train, y_train, X_test, y_test = utils.split_data(X, y)\n",
        "vocab_size = X.shape[1]\n",
        "n_classes = y.shape[1]\n",
        "\n",
        "print(\"Tweet:\", sentences[5])\n",
        "print(\"Label:\", y[5])\n",
        "print(\"Bag of Words Representation:\", X_train[5])\n",
        "\n",
        "data_placeholder = tf.placeholder(tf.float32, shape=(None, vocab_size), name='data_placeholder')\n",
        "\n",
        "'''TODO: Make the labels placeholder.''';\n",
        "labels_placeholder = tf.placeholder(tf.float32, shape=(None, n_classes), name='labels_placeholder')\n",
        "\n",
        "\n",
        "# Define Network Parameters\n",
        "\n",
        "# Here, we can define how many units will be in each hidden layer.\n",
        "n_hidden_units_h0 = 512\n",
        "n_hidden_units_h1 = 256\n",
        "\n",
        "# Weights going from input to first hidden layer.\n",
        "# The first value passed into tf.Variable is initialization of the variable.\n",
        "# We initialize our weights to be sampled from a truncated normal, as this does something\n",
        "# called symmetry breaking and keeps the neural network from getting stuck at the start.\n",
        "# Since the weight matrix multiplies the previous layer to get inputs to the next layer,\n",
        "# its size is prev_layer_size x next_layer_size.\n",
        "h0_weights = tf.Variable(\n",
        "    tf.truncated_normal([vocab_size, n_hidden_units_h0]),\n",
        "    name='h0_weights')\n",
        "h0_biases = tf.Variable(tf.zeros([n_hidden_units_h0]),\n",
        "                     name='h0_biases')\n",
        "\n",
        "'''TODO: Set up variables for the weights going into the second hidden layer.\n",
        "You can check out the tf.Variable API here: https://www.tensorflow.org/api_docs/python/tf/Variable.\n",
        "''';\n",
        "h1_weights = tf.Variable(\n",
        "    tf.truncated_normal([n_hidden_units_h0, n_hidden_units_h1]),\n",
        "    name='h1_weights')\n",
        "h1_biases = tf.Variable(tf.zeros([n_hidden_units_h1]),\n",
        "                     name='h1_biases')\n",
        "\n",
        "# Weights going into the output layer.\n",
        "out_weights = tf.Variable(\n",
        "    tf.truncated_normal([n_hidden_units_h1, n_classes]),\n",
        "    name='out_weights')\n",
        "out_biases = tf.Variable(tf.zeros([n_classes]),\n",
        "                     name='out_biases')\n",
        "\n",
        "# Define Computation Graphs\n",
        "hidden0 = tf.nn.relu(tf.matmul(data_placeholder, h0_weights) + h0_biases)\n",
        "\n",
        "'''TODO: write the computation to get the output of the second hidden layer.''';\n",
        "hidden1 = tf.nn.relu(tf.matmul(hidden0, h1_weights) + h1_biases)\n",
        "\n",
        "logits = tf.matmul(hidden1, out_weights) + out_biases\n",
        "\n",
        "'''TODO: Define the loss.  Use tf.nn.softmax_cross_entropy_with_logits.'''\n",
        "loss = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_placeholder))\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# Define the optimizer operation.  This is what will take the derivate of the loss\n",
        "# with respect to each of our parameters and try to minimize it.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Compute the accuracy\n",
        "prediction_is_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_placeholder, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction_is_correct, tf.float32))\n",
        "\n",
        "num_steps = 3000\n",
        "batch_size = 128\n",
        "\n",
        "with tf.Session() as session:\n",
        "\n",
        "    # this operation initializes all the variables we made earlier.\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        # Generate a minibatch.\n",
        "        offset = (step * batch_size) % (X_train.shape[0] - batch_size)\n",
        "        batch_data = X_train[offset:(offset + batch_size), :]\n",
        "        batch_labels = y_train[offset:(offset + batch_size), :]\n",
        "\n",
        "        # Create a dictionary to pass in the batch data.\n",
        "        feed_dict_train = {data_placeholder: batch_data, labels_placeholder : batch_labels}\n",
        "\n",
        "        # Run the optimizer, the loss, the predictions.\n",
        "        # We can run multiple things at once and get their outputs.\n",
        "        _, loss_value_train, predictions_value_train, accuracy_value_train = session.run(\n",
        "          [optimizer, loss, prediction, accuracy], feed_dict=feed_dict_train)\n",
        "\n",
        "        # Print stuff every once in a while.\n",
        "        if (step % 100 == 0):\n",
        "            print(\"Minibatch train loss at step\", step, \":\", loss_value_train)\n",
        "            print(\"Minibatch train accuracy: %.3f%%\" % (accuracy_value_train*100))\n",
        "            feed_dict_test = {data_placeholder: X_test, labels_placeholder: y_test}\n",
        "            loss_value_test, predictions_value_test, accuracy_value_test = session.run(\n",
        "                [loss, prediction, accuracy], feed_dict=feed_dict_test)\n",
        "            print(\"Test loss: %.3f\" % loss_value_test)\n",
        "            print(\"Test accuracy: %.3f%%\" % (accuracy_value_test*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ftg9glal6CT6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "name": "_merged",
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}